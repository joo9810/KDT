{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>본죽&amp;비빔밥에서 전복죽 하나랑 소고기비빔밥 하나, 그리고 추가로 깍두기 리필 부탁드...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>한솥에서 치킨마요 두 개랑 닭가슴살 샐러드 하나 주문이요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>본죽에서 단호박죽 하나랑 팥죽 하나 추가해주세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>두찜에서 치즈찜닭 하나랑 순살 찜닭 소자, 공깃밥 두 개 추가요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>땅스부대찌개에서 베이컨 부대찌개 2인분, 라면사리 두 개 넣어주세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>죽 한 그릇과 공깃밥 명품죽에서 시킬게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>미역국 한 그릇과 공깃밥 착한미역국에서 주문할게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>낙지탕 하나와 공깃밥 낙곱상회에서 시킬게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>감자탕 한 그릇과 공깃밥 대한감자탕에서 주문할게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>정성 담은 음식 정성담에서 시킬게요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     본죽&비빔밥에서 전복죽 하나랑 소고기비빔밥 하나, 그리고 추가로 깍두기 리필 부탁드...\n",
       "1                      한솥에서 치킨마요 두 개랑 닭가슴살 샐러드 하나 주문이요.\n",
       "2                           본죽에서 단호박죽 하나랑 팥죽 하나 추가해주세요.\n",
       "3                  두찜에서 치즈찜닭 하나랑 순살 찜닭 소자, 공깃밥 두 개 추가요.\n",
       "4                땅스부대찌개에서 베이컨 부대찌개 2인분, 라면사리 두 개 넣어주세요.\n",
       "...                                                 ...\n",
       "2595                            죽 한 그릇과 공깃밥 명품죽에서 시킬게요.\n",
       "2596                       미역국 한 그릇과 공깃밥 착한미역국에서 주문할게요.\n",
       "2597                           낙지탕 하나와 공깃밥 낙곱상회에서 시킬게요.\n",
       "2598                       감자탕 한 그릇과 공깃밥 대한감자탕에서 주문할게요.\n",
       "2599                               정성 담은 음식 정성담에서 시킬게요.\n",
       "\n",
       "[2600 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text1 = pd.read_table('text.txt')\n",
    "text1['text'] = text1['text'].apply(lambda x : x.replace(\"'\", ''))\n",
    "text1['text'] = text1['text'].apply(lambda x : x.replace('\"', ''))\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한', '솥', '에서', '치킨', '마요', '두', '개', '랑', '닭', '가슴살', '샐러드', '하나', '주문', '이', '요', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "merge_word = ['한솥']\n",
    "\n",
    "dicpath = '/opt/homebrew/lib/mecab/dic/mecab-ko-dic'\n",
    "mecab = Mecab(dicpath + \" -r /opt/homebrew/etc/mecabrc\")\n",
    "token = mecab.morphs(text1['text'][1])\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 토큰 단위로 쪼개는 방법\n",
    "# from konlpy.tag import Mecab\n",
    "\n",
    "# text = pd.read_table('text.txt')\n",
    "# text['text'] = text['text'].apply(lambda x : x.replace(\"'\", ''))\n",
    "# text['text'] = text['text'].apply(lambda x : x.replace('\"', ''))\n",
    "# tokens_list = []\n",
    "# dicpath = '/opt/homebrew/lib/mecab/dic/mecab-ko-dic'\n",
    "# mecab = Mecab(dicpath + \" -r /opt/homebrew/etc/mecabrc\")\n",
    "# for i in text['text']:\n",
    "#     tokens = mecab.morphs(i)\n",
    "#     tokens_list.append(tokens)\n",
    "\n",
    "# with open('ner.json', 'w', encoding='utf-8') as f:\n",
    "#     f.write('[\\n')\n",
    "#     for index, i in enumerate(tokens_list):\n",
    "#         f.write('  {\\n')\n",
    "#         formatted_string = str(i).replace(\"'\", '\"')\n",
    "#         f.write(f'    \"tokens\" : {formatted_string},\\n')\n",
    "#         f.write(f'    \"ner_tags\" : {[0] * len(i)}\\n')\n",
    "#         if index != (len(tokens_list)-1):\n",
    "#             f.write('  },\\n')\n",
    "#         else:\n",
    "#             f.write('  }\\n')\n",
    "#     f.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 한 글자 단위로 쪼개는 방법\n",
    "# from konlpy.tag import Mecab\n",
    "\n",
    "# text = pd.read_table('text.txt')\n",
    "# text['text'] = text['text'].apply(lambda x : x.replace(\"'\", ''))\n",
    "# text['text'] = text['text'].apply(lambda x : x.replace('\"', ''))\n",
    "# tokens_list = []\n",
    "# for i in text['text']:\n",
    "#     tokens = [word for word in i if word != ' ']\n",
    "#     tokens_list.append(tokens)\n",
    "\n",
    "# with open('ner1.json', 'w', encoding='utf-8') as f:\n",
    "#     f.write('[\\n')\n",
    "#     for index, i in enumerate(tokens_list):\n",
    "#         f.write('  {\\n')\n",
    "#         formatted_string = str(i).replace(\"'\", '\"')\n",
    "#         f.write(f'    \"tokens\" : {formatted_string},\\n')\n",
    "#         f.write(f'    \"ner_tags\" : {[0] * len(i)}\\n')\n",
    "#         if index != (len(tokens_list)-1):\n",
    "#             f.write('  },\\n')\n",
    "#         else:\n",
    "#             f.write('  }\\n')\n",
    "#     f.write(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okt : ['하지만', '음식', '주문', '텍스트', '를', '수집', '하기가', '힘들어서', '자연스러운', '음식', '주문', '텍스트', '를', '100', '개', '생', '성해줘', '.']\n",
      "Mecab : ['하지만', '음식', '주문', '텍스트', '를', '수집', '하', '기', '가', '힘들', '어서', '자연', '스러운', '음식', '주문', '텍스트', '를', '100', '개', '생성', '해', '줘', '.']\n",
      "Kkma : ['하지만', '음식', '주문', '텍스트', '를', '수집', '하', '기', '가', '힘들', '어서', '자연', '스럽', 'ㄴ', '음식', '주문', '텍스트', '를', '100', '개', '생성', '하', '어', '주', '어', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt, Mecab, Kkma\n",
    "\n",
    "index = 0\n",
    "\n",
    "okt = Okt()\n",
    "dicpath = '/opt/homebrew/lib/mecab/dic/mecab-ko-dic'\n",
    "mecab = Mecab(dicpath + \" -r /opt/homebrew/etc/mecabrc\")\n",
    "kkma = Kkma()\n",
    "text = pd.read_table('./text/order_text.txt')\n",
    "tokens1 = okt.morphs(text.iloc[index][0])\n",
    "tokens2 = mecab.morphs(text.iloc[index][0])\n",
    "tokens3 = kkma.morphs(text.iloc[index][0])\n",
    "print(f\"Okt : {tokens1}\")\n",
    "print(f\"Mecab : {tokens2}\")\n",
    "print(f\"Kkma : {tokens3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[본죽, &amp;, 비빔밥, 에서, 전복죽, 하나, 랑, 소고기, 비빔밥, 하나, ,, ...</td>\n",
       "      <td>[1, 2, 2, 0, 3, 5, 0, 3, 4, 5, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[한, 솥, 에서, 치킨, 마요, 두, 개, 랑, 닭, 가슴살, 샐러드, 하나, 주...</td>\n",
       "      <td>[1, 2, 0, 3, 4, 5, 6, 0, 3, 4, 4, 5, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[본죽, 에서, 단, 호박죽, 하나, 랑, 팥죽, 하나, 추가, 해, 주, 세요, .]</td>\n",
       "      <td>[1, 0, 3, 4, 5, 0, 3, 5, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[두, 찜, 에서, 치즈, 찜, 닭, 하나, 랑, 순, 살, 찜, 닭, 소자, ,,...</td>\n",
       "      <td>[1, 2, 0, 3, 4, 4, 5, 0, 3, 4, 4, 4, 4, 0, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[땅, 스, 부대찌개, 에서, 베이컨, 부대찌개, 2, 인분, ,, 라면, 사리, ...</td>\n",
       "      <td>[1, 2, 2, 0, 3, 4, 5, 6, 0, 3, 4, 5, 6, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>[죽, 한, 그릇, 과, 공깃밥, 명품, 죽, 에서, 시킬, 게, 요, .]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>[미역국, 한, 그릇, 과, 공깃밥, 착한, 미역국, 에서, 주문, 할게요, .]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>[낙지, 탕, 하나, 와, 공깃밥, 낙, 곱, 상회, 에서, 시킬, 게, 요, .]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>[감자탕, 한, 그릇, 과, 공깃밥, 대한, 감자탕, 에서, 주문, 할게요, .]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>[정성, 담, 은, 음식, 정성, 담, 에서, 시킬, 게, 요, .]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [본죽, &, 비빔밥, 에서, 전복죽, 하나, 랑, 소고기, 비빔밥, 하나, ,, ...   \n",
       "1     [한, 솥, 에서, 치킨, 마요, 두, 개, 랑, 닭, 가슴살, 샐러드, 하나, 주...   \n",
       "2      [본죽, 에서, 단, 호박죽, 하나, 랑, 팥죽, 하나, 추가, 해, 주, 세요, .]   \n",
       "3     [두, 찜, 에서, 치즈, 찜, 닭, 하나, 랑, 순, 살, 찜, 닭, 소자, ,,...   \n",
       "4     [땅, 스, 부대찌개, 에서, 베이컨, 부대찌개, 2, 인분, ,, 라면, 사리, ...   \n",
       "...                                                 ...   \n",
       "2595         [죽, 한, 그릇, 과, 공깃밥, 명품, 죽, 에서, 시킬, 게, 요, .]   \n",
       "2596      [미역국, 한, 그릇, 과, 공깃밥, 착한, 미역국, 에서, 주문, 할게요, .]   \n",
       "2597     [낙지, 탕, 하나, 와, 공깃밥, 낙, 곱, 상회, 에서, 시킬, 게, 요, .]   \n",
       "2598      [감자탕, 한, 그릇, 과, 공깃밥, 대한, 감자탕, 에서, 주문, 할게요, .]   \n",
       "2599             [정성, 담, 은, 음식, 정성, 담, 에서, 시킬, 게, 요, .]   \n",
       "\n",
       "                                               ner_tags  \n",
       "0     [1, 2, 2, 0, 3, 5, 0, 3, 4, 5, 0, 0, 0, 0, 0, ...  \n",
       "1      [1, 2, 0, 3, 4, 5, 6, 0, 3, 4, 4, 5, 0, 0, 0, 0]  \n",
       "2               [1, 0, 3, 4, 5, 0, 3, 5, 0, 0, 0, 0, 0]  \n",
       "3     [1, 2, 0, 3, 4, 4, 5, 0, 3, 4, 4, 4, 4, 0, 3, ...  \n",
       "4     [1, 2, 2, 0, 3, 4, 5, 6, 0, 3, 4, 5, 6, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2595               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2596                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2597            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2598                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2599                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[2600 rows x 2 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pd.read_json('ner.json')\n",
    "ner_tokens = ner['tokens']\n",
    "# for i in ner_tokens[:100]:\n",
    "#     print(i)\n",
    "ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m formatted_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformatted_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mner_tag_list[index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(tokens_list)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     59\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 토크나이저 태깅에서 한 글자 태깅으로 전환할때\n",
    "def make_ner_tag(token, ner_tag):\n",
    "    new_ner_tag = []\n",
    "    for i, j in zip(token, ner_tag):\n",
    "        if (len(i) >= 2) & (j == 1):\n",
    "                new_ner_tag.append(1)\n",
    "                for z in range(len(i)-1):\n",
    "                    new_ner_tag.append(2)\n",
    "        elif (len(i) >= 2) & (j == 3):\n",
    "                new_ner_tag.append(3)\n",
    "                for z in range(len(i)-1):\n",
    "                    new_ner_tag.append(4)\n",
    "        elif (len(i) >= 2) & (j == 5):\n",
    "                new_ner_tag.append(5)\n",
    "                for z in range(len(i)-1):\n",
    "                    new_ner_tag.append(6)\n",
    "        elif (len(i) >= 2) & (j == 0):\n",
    "            for z in range(len(i)):\n",
    "                new_ner_tag.append(j)\n",
    "        elif (len(i) >= 2) & (j == 2):\n",
    "            for z in range(len(i)):\n",
    "                new_ner_tag.append(j)          \n",
    "        elif (len(i) >= 2) & (j == 4):\n",
    "            for z in range(len(i)):\n",
    "                new_ner_tag.append(j)\n",
    "        elif (len(i) >= 2) & (j == 6):\n",
    "            for z in range(len(i)):\n",
    "                new_ner_tag.append(j)  \n",
    "        elif len(i) == 1:\n",
    "            new_ner_tag.append(j)\n",
    "    return new_ner_tag\n",
    "\n",
    "ner = pd.read_json('character_train_2.json')\n",
    "ner_tag_list = []\n",
    "for i, j in zip(ner['tokens'], ner['ner_tags']):\n",
    "    ner_tag_list.append(make_ner_tag(i, j))\n",
    "# print(ner_tag_list)\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "text = pd.read_table('text.txt')\n",
    "text['text'] = text['text'].apply(lambda x : x.replace(\"'\", ''))\n",
    "text['text'] = text['text'].apply(lambda x : x.replace('\"', ''))\n",
    "tokens_list = []\n",
    "for i in text['text']:\n",
    "    tokens = [word for word in i if word != ' ']\n",
    "    tokens_list.append(tokens)\n",
    "\n",
    "with open('character_train_2.json', 'w', encoding='utf-8') as f:\n",
    "    f.write('[\\n')\n",
    "    for index, i in enumerate(tokens_list):\n",
    "        f.write('  {\\n')\n",
    "        formatted_string = str(i).replace(\"'\", '\"')\n",
    "        f.write(f'    \"tokens\" : {formatted_string},\\n')\n",
    "        f.write(f'    \"ner_tags\" : {ner_tag_list[index]}\\n')\n",
    "        if index != (len(tokens_list)-1):\n",
    "            f.write('  },\\n')\n",
    "        else:\n",
    "            f.write('  }\\n')\n",
    "    f.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_TEXT_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
